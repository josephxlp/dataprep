{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b53e2c9",
   "metadata": {},
   "source": [
    "1. data [x]\n",
    "    - get the vrts for esa,ldar,s1,edem [x]\n",
    "    - get the tifs from tls and rng [x]\n",
    "\n",
    "2. datapre [+]\n",
    "    - clip by bbox [x] \n",
    "    - split train from test (cpu modelling continual ml?)\n",
    "\n",
    "3. datamod [tab]\n",
    "    - step 1: predit ldem \n",
    "    - step 2: get scores for with and without residual \n",
    "    - step 3: style transfer (+residual)\n",
    "    - step 4: expand prediction range by N pixels same model \n",
    "    - step 5: data fusion with ldem\n",
    "4. datamod [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb77685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2af5d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdir4749 =  \"/media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749\"  \n",
    "ldem_vrt = f\"{outdir4749}/ldem_4749.vrt\"\n",
    "cmd = f\"gdalbuildvrt -overwrite {ldem_vrt} {outdir4749}/*.tif\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d99ac9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "esawc_vrt = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/esawc/esawc.vrt\"\n",
    "s1_vrt = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/s1/s1.vrt\"\n",
    "edem_egm_vrt = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/edem_egm/edem_egm.vrt\" \n",
    "\n",
    "tls_fn = \"/media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749/AngkorDTM50cm.tif\"\n",
    "rng_files = glob(\"/media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749/*.tif\")\n",
    "rgn_files = [f for f in rng_files if \"AngkorDTM50cm\" not in f and \"delta_s_m2070\" not in f]\n",
    "\n",
    "vrt_files = [esawc_vrt, s1_vrt,edem_egm_vrt, ldem_vrt] # these are the vrt files \n",
    "temp_dir = 'temp'\n",
    "os.makedirs(temp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a97ff",
   "metadata": {},
   "source": [
    "esawc_vrt, s1_vrt,edem_egm_vrt  and tls_fn #set for self supervision SSL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7c52987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference GeoTIFF: /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749/AngkorDTM50cm.tif\n",
      "  Bounding box: BoundingBox(left=103.73573115613353, bottom=13.317802380912203, right=103.99762004502242, top=13.47535793646776)\n",
      "  Transform: | 0.00, 0.00, 103.74|\n",
      "| 0.00,-0.00, 13.48|\n",
      "| 0.00, 0.00, 1.00|\n",
      "  Width: 2357, Height: 1418\n",
      "\n",
      "Processing /media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/esawc/esawc.vrt...\n",
      "  Saved aligned data to temp/aligned_esawc.tif\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 00:34:47,149 - WARNING - CPLE_AppDefined:tile_6400_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,158 - WARNING - CPLE_AppDefined:tile_6400_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,166 - WARNING - CPLE_AppDefined:tile_6400_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,174 - WARNING - CPLE_AppDefined:tile_6400_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,183 - WARNING - CPLE_AppDefined:tile_6400_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,191 - WARNING - CPLE_AppDefined:tile_6656_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,201 - WARNING - CPLE_AppDefined:tile_6656_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,211 - WARNING - CPLE_AppDefined:tile_6656_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,219 - WARNING - CPLE_AppDefined:tile_6656_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,228 - WARNING - CPLE_AppDefined:tile_6656_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,237 - WARNING - CPLE_AppDefined:tile_6912_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,245 - WARNING - CPLE_AppDefined:tile_6912_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,254 - WARNING - CPLE_AppDefined:tile_6912_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,262 - WARNING - CPLE_AppDefined:tile_6912_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,271 - WARNING - CPLE_AppDefined:tile_6912_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,280 - WARNING - CPLE_AppDefined:tile_6912_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,288 - WARNING - CPLE_AppDefined:tile_7168_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,297 - WARNING - CPLE_AppDefined:tile_7168_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,305 - WARNING - CPLE_AppDefined:tile_7168_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,314 - WARNING - CPLE_AppDefined:tile_7168_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,322 - WARNING - CPLE_AppDefined:tile_7168_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing /media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/s1/s1.vrt...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-29 00:34:47,331 - WARNING - CPLE_AppDefined:tile_7168_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,339 - WARNING - CPLE_AppDefined:tile_7424_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,348 - WARNING - CPLE_AppDefined:tile_7424_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,356 - WARNING - CPLE_AppDefined:tile_7424_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,365 - WARNING - CPLE_AppDefined:tile_7424_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,374 - WARNING - CPLE_AppDefined:tile_7424_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,382 - WARNING - CPLE_AppDefined:tile_7424_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,391 - WARNING - CPLE_AppDefined:tile_7680_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,399 - WARNING - CPLE_AppDefined:tile_7680_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,408 - WARNING - CPLE_AppDefined:tile_7680_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,417 - WARNING - CPLE_AppDefined:tile_7680_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,425 - WARNING - CPLE_AppDefined:tile_7680_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,434 - WARNING - CPLE_AppDefined:tile_6400_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,442 - WARNING - CPLE_AppDefined:tile_6656_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,450 - WARNING - CPLE_AppDefined:tile_7936_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,458 - WARNING - CPLE_AppDefined:tile_7936_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,466 - WARNING - CPLE_AppDefined:tile_7936_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,476 - WARNING - CPLE_AppDefined:tile_7936_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,485 - WARNING - CPLE_AppDefined:tile_7936_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,495 - WARNING - CPLE_AppDefined:tile_7936_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,505 - WARNING - CPLE_AppDefined:tile_8192_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,515 - WARNING - CPLE_AppDefined:tile_8192_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,525 - WARNING - CPLE_AppDefined:tile_8192_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,535 - WARNING - CPLE_AppDefined:tile_8192_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,545 - WARNING - CPLE_AppDefined:tile_8192_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,555 - WARNING - CPLE_AppDefined:tile_8192_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,565 - WARNING - CPLE_AppDefined:tile_8448_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,575 - WARNING - CPLE_AppDefined:tile_8448_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,586 - WARNING - CPLE_AppDefined:tile_8448_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,597 - WARNING - CPLE_AppDefined:tile_8448_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,607 - WARNING - CPLE_AppDefined:tile_8448_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,617 - WARNING - CPLE_AppDefined:tile_8448_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,627 - WARNING - CPLE_AppDefined:tile_8704_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,637 - WARNING - CPLE_AppDefined:tile_8704_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,648 - WARNING - CPLE_AppDefined:tile_8704_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,658 - WARNING - CPLE_AppDefined:tile_8704_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,668 - WARNING - CPLE_AppDefined:tile_8704_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,678 - WARNING - CPLE_AppDefined:tile_7680_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,689 - WARNING - CPLE_AppDefined:tile_8704_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,699 - WARNING - CPLE_AppDefined:tile_8960_4608_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,708 - WARNING - CPLE_AppDefined:tile_8960_4864_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,718 - WARNING - CPLE_AppDefined:tile_8960_5120_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,727 - WARNING - CPLE_AppDefined:tile_8960_5376_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,736 - WARNING - CPLE_AppDefined:tile_8960_5632_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n",
      "2025-04-29 00:34:47,746 - WARNING - CPLE_AppDefined:tile_8960_5888_S1_VVVH.tif: TIFFReadDirectory:Sum of Photometric type-related color channels and ExtraSamples doesn't match SamplesPerPixel. Defining non-color channels as ExtraSamples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved aligned data to temp/aligned_s1.tif\n",
      "\n",
      "Processing /media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/edem_egm/edem_egm.vrt...\n",
      "  Saved aligned data to temp/aligned_edem_egm.tif\n",
      "\n",
      "Processing /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749/ldem_4749.vrt...\n",
      "  Saved aligned data to temp/aligned_ldem_4749.tif\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "def daug_isolate_data_box(tls_fn, vrt_files, temp_dir):\n",
    "    \"\"\"\n",
    "    Reads data from VRT files, aligning their spatial information and pixel counts\n",
    "    with a GeoTIFF file, and saves the extracted data as new GeoTIFF files.\n",
    "\n",
    "    Args:\n",
    "        tls_fn (str): Path to the reference GeoTIFF file.\n",
    "        vrt_files (list): List of paths to the VRT files to process.\n",
    "        temp_dir (str): Path to the directory where the output GeoTIFF files will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Open the reference GeoTIFF file to get spatial information\n",
    "        with rasterio.open(tls_fn) as tls_dataset:\n",
    "            # Get the bounding box, transform, width, and height of the reference GeoTIFF\n",
    "            bbox = tls_dataset.bounds\n",
    "            transform = tls_dataset.transform\n",
    "            out_width = tls_dataset.width\n",
    "            out_height = tls_dataset.height\n",
    "            print(f\"Reference GeoTIFF: {tls_fn}\")\n",
    "            print(f\"  Bounding box: {bbox}\")\n",
    "            print(f\"  Transform: {transform}\")\n",
    "            print(f\"  Width: {out_width}, Height: {out_height}\")\n",
    "\n",
    "            # Process each VRT file\n",
    "            for vrt_file in vrt_files:\n",
    "                try:\n",
    "                    # Open the VRT file\n",
    "                    with rasterio.open(vrt_file) as vrt_dataset:\n",
    "                        print(f\"\\nProcessing {vrt_file}...\")\n",
    "\n",
    "                        # Calculate the window based on the bounding box and transform of the reference GeoTIFF\n",
    "                        window = from_bounds(bbox.left, bbox.bottom, bbox.right, bbox.top, vrt_dataset.transform)\n",
    "\n",
    "                        # Read the data within the calculated window\n",
    "                        # Specify the desired output shape to ensure alignment\n",
    "                        try:\n",
    "                            data = vrt_dataset.read(window=window, out_shape=(vrt_dataset.count, out_height, out_width))\n",
    "                        except ValueError as e:\n",
    "                            print(f\"  Error reading data from {vrt_file} within the window: {e}\")\n",
    "                            print(\"  This might indicate a significant spatial mismatch.\")\n",
    "                            data = None\n",
    "\n",
    "                        if data is not None:\n",
    "                            # Update the metadata for the output GeoTIFF file\n",
    "                            out_meta = vrt_dataset.meta.copy()\n",
    "                            out_meta.update({\n",
    "                                \"driver\": \"GTiff\",\n",
    "                                \"height\": out_height,\n",
    "                                \"width\": out_width,\n",
    "                                \"transform\": transform,\n",
    "                                \"dtype\": data.dtype,\n",
    "                            })\n",
    "\n",
    "                            # Check for valid dimensions before writing\n",
    "                            if out_height > 0 and out_width > 0:\n",
    "                                # Create the output file name\n",
    "                                output_filename = os.path.join(temp_dir, f\"aligned_{os.path.basename(vrt_file)}\")\n",
    "                                output_filename = os.path.splitext(output_filename)[0] + \".tif\"\n",
    "\n",
    "                                # Write the data to a new GeoTIFF file\n",
    "                                with rasterio.open(output_filename, \"w\", **out_meta) as dst:\n",
    "                                    dst.write(data)\n",
    "                                print(f\"  Saved aligned data to {output_filename}\")\n",
    "                            else:\n",
    "                                print(f\"  Skipping {vrt_file}: Output dimensions are invalid (height={out_height}, width={out_width}).\")\n",
    "                                output_filename = os.path.join(temp_dir, f\"aligned_{os.path.basename(vrt_file)}\")\n",
    "                                output_filename = os.path.splitext(output_filename)[0] + \".tif\"\n",
    "                                shutil.copyfile(tls_fn, output_filename)\n",
    "                                print(f\"  Copied {tls_fn} to {output_filename} as a fallback.\")\n",
    "                        else:\n",
    "                            print(f\"  Skipping {vrt_file} due to issues reading data.\")\n",
    "                            output_filename = os.path.join(temp_dir, f\"aligned_{os.path.basename(vrt_file)}\")\n",
    "                            output_filename = os.path.splitext(output_filename)[0] + \".tif\"\n",
    "                            shutil.copyfile(tls_fn, output_filename)\n",
    "                            print(f\"  Copied {tls_fn} to {output_filename} as a fallback.\")\n",
    "\n",
    "                except rasterio.RasterioIOError as e:\n",
    "                    print(f\"  Error processing {vrt_file}: {e}\")\n",
    "                    print(f\"  Skipping {vrt_file} and continuing. Check if the file exists and is a valid raster.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  An unexpected error occurred while processing {vrt_file}: {e}\")\n",
    "\n",
    "    except rasterio.RasterioIOError as e:\n",
    "        print(f\"Error opening {tls_fn}: {e}\")\n",
    "        print(\"Please ensure the file path is correct and the file is a valid GeoTIFF.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred with the reference GeoTIFF: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  \n",
    "    # Create a temporary directory if it doesn't exist\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "\n",
    "    process_raster_data(tls_fn, vrt_files, temp_dir)\n",
    "\n",
    "    # Clean up the temporary directory after processing (optional)\n",
    "    # shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656346ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def load_geotiff(file_path):\n",
    "    dataset = rasterio.open(file_path)\n",
    "    data = dataset.read()\n",
    "    return dataset, data\n",
    "\n",
    "\n",
    "def preprocess_data(s1_data, esawc_data, ldem_data):\n",
    "    s1_flat = s1_data.reshape(s1_data.shape[0], -1).T\n",
    "    esawc_flat = esawc_data.reshape(esawc_data.shape[0], -1).T\n",
    "    ldem_flat = ldem_data.reshape(ldem_data.shape[0], -1).T\n",
    "\n",
    "    if s1_flat.shape[0] != esawc_flat.shape[0] or s1_flat.shape[0] != ldem_flat.shape[0]:\n",
    "        raise ValueError(\"Number of pixels in s1, esawc, and ldem do not match.\")\n",
    "\n",
    "    features = np.concatenate((s1_flat, esawc_flat), axis=1)\n",
    "    valid_indices = ~np.isnan(ldem_flat).any(axis=1)\n",
    "    features_filtered = features[valid_indices]\n",
    "    labels_filtered = ldem_flat[valid_indices].ravel()\n",
    "    return features_filtered, labels_filtered\n",
    "\n",
    "\n",
    "\n",
    "def train_model(features, labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = lgb.LGBMRegressor(random_state=42)\n",
    "    model.fit(features, labels)\n",
    "    score = model.score(X_test, y_test)\n",
    "    logger.info(f\"Model R^2 Score: {score}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def predict_and_save(model, features, edem_dataset, output_path):\n",
    "    edem_data = edem_dataset.read()\n",
    "    predictions_flat = model.predict(features)\n",
    "    predictions = predictions_flat.reshape(edem_data.shape[1], edem_data.shape[2])\n",
    "    profile = edem_dataset.profile.copy()\n",
    "    profile.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1,\n",
    "        height=predictions.shape[0],\n",
    "        width=predictions.shape[1],\n",
    "    )\n",
    "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(predictions, 1)\n",
    "\n",
    "\n",
    "# add timer when bfore and after the function \n",
    "# add other function to select the model if RF, XGBoost, CatBoost, LightGBM, etc\n",
    "# add option to chose features , e.g. [s1, esawc, edem] or [s1,esawc], or ['edem'] and only select the features give \n",
    "# save the model with paramers as name of the features and num_of_iterations \n",
    "def train_and_predict_lightgbm(temp_dir, output_dir, output_filename=\"lgbm_predictions.tif\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    s1_path = os.path.join(temp_dir, \"aligned_s1.tif\")\n",
    "    esawc_path = os.path.join(temp_dir, \"aligned_esawc.tif\")\n",
    "    ldem_path = os.path.join(temp_dir, \"aligned_ldem_4749.tif\")\n",
    "    edem_path = os.path.join(temp_dir, \"aligned_edem_egm.tif\")\n",
    "\n",
    "    try:\n",
    "        s1_dataset, s1_data = load_geotiff(s1_path)\n",
    "        esawc_dataset, esawc_data = load_geotiff(esawc_path)\n",
    "        ldem_dataset, ldem_data = load_geotiff(ldem_path)\n",
    "        edem_dataset, edem_data = load_geotiff(edem_path)\n",
    "\n",
    "        features, labels = preprocess_data(s1_data, esawc_data, ldem_data)\n",
    "\n",
    "        model = train_model(features, labels)\n",
    "\n",
    "        model_filename = os.path.join(output_dir, \"lightgbm_model.joblib\")\n",
    "        joblib.dump(model, model_filename)\n",
    "\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        predict_and_save(model, features, edem_dataset, output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        if 's1_dataset' in locals(): s1_dataset.close()\n",
    "        if 'esawc_dataset' in locals(): esawc_dataset.close()\n",
    "        if 'ldem_dataset' in locals(): ldem_dataset.close()\n",
    "        if 'edem_dataset' in locals(): edem_dataset.close()\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     output_dir = os.path.join(temp_dir, \"output\")\n",
    "#     train_and_predict_lightgbm(temp_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574ba39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695750f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73a290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the temp directory load s1 and esacf as features and ldem as label\n",
    "# remove the missing values filtering out the no data values by ldem \n",
    "# fit random forest model \n",
    "# save the model \n",
    "# make predictions on the entire feature set \n",
    "# write the predictions to a new tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 18:39:48,874 - INFO - Starting train_and_predict...\n",
      "2025-04-28 18:39:48,876 - INFO - Starting load_geotiff...\n",
      "2025-04-28 18:39:48,901 - INFO - Finished load_geotiff in 0.03 seconds.\n",
      "2025-04-28 18:39:48,902 - INFO - Starting load_geotiff...\n",
      "2025-04-28 18:39:48,926 - INFO - Finished load_geotiff in 0.02 seconds.\n",
      "2025-04-28 18:39:48,927 - INFO - Starting load_geotiff...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 18:39:48,956 - INFO - Finished load_geotiff in 0.03 seconds.\n",
      "2025-04-28 18:39:48,958 - INFO - Starting preprocess_data...\n",
      "2025-04-28 18:39:49,022 - INFO - Finished preprocess_data in 0.06 seconds.\n",
      "2025-04-28 18:39:49,023 - INFO - Starting train_model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2673780, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 58726557525220922143210296142894989312.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 18:39:51,104 - INFO - LIGHTGBM Model R^2 Score: -0.6119\n",
      "2025-04-28 18:39:51,106 - INFO - Finished train_model in 2.08 seconds.\n",
      "2025-04-28 18:39:51,111 - INFO - Model saved to temp/output/lightgbm_edem_3342226samples.joblib\n",
      "2025-04-28 18:39:51,111 - INFO - Starting predict_and_save...\n",
      "2025-04-28 18:39:52,244 - INFO - Finished predict_and_save in 1.13 seconds.\n",
      "2025-04-28 18:39:52,247 - INFO - Finished train_and_predict in 3.37 seconds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setup logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        logger.info(f\"Starting {func.__name__}...\")\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        logger.info(f\"Finished {func.__name__} in {end - start:.2f} seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def load_geotiff(file_path):\n",
    "    dataset = rasterio.open(file_path)\n",
    "    data = dataset.read()\n",
    "    return dataset, data\n",
    "\n",
    "def select_features(feature_list, datasets):\n",
    "    feature_arrays = []\n",
    "    for feature in feature_list:\n",
    "        data = datasets[feature]\n",
    "        feature_arrays.append(data.reshape(data.shape[0], -1).T)\n",
    "    combined_features = np.concatenate(feature_arrays, axis=1)\n",
    "    return combined_features\n",
    "\n",
    "@timer\n",
    "def preprocess_data(feature_list, datasets, ldem_data):\n",
    "    features = select_features(feature_list, datasets)\n",
    "    ldem_flat = ldem_data.reshape(ldem_data.shape[0], -1).T\n",
    "    if features.shape[0] != ldem_flat.shape[0]:\n",
    "        raise ValueError(\"Mismatch in number of pixels between features and labels.\")\n",
    "    valid_indices = ~np.isnan(ldem_flat).any(axis=1)\n",
    "    features_filtered = features[valid_indices]\n",
    "    labels_filtered = ldem_flat[valid_indices].ravel()\n",
    "    return features_filtered, labels_filtered\n",
    "\n",
    "def get_model(model_type):\n",
    "    if model_type == \"lightgbm\":\n",
    "        return lgb.LGBMRegressor(random_state=42)\n",
    "    elif model_type == \"xgboost\":\n",
    "        return xgb.XGBRegressor(random_state=42)\n",
    "    elif model_type == \"catboost\":\n",
    "        return cb.CatBoostRegressor(verbose=0, random_state=42)\n",
    "    elif model_type == \"rf\":\n",
    "        return RandomForestRegressor(random_state=42)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "@timer\n",
    "def train_model(features, labels, model_type=\"lightgbm\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    model = get_model(model_type)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    logger.info(f\"{model_type.upper()} Model R^2 Score: {score:.4f}\")\n",
    "    return model\n",
    "\n",
    "@timer\n",
    "def predict_and_save(model, features, edem_dataset, output_path):\n",
    "    edem_data = edem_dataset.read()\n",
    "    predictions_flat = model.predict(features)\n",
    "    predictions = predictions_flat.reshape(edem_data.shape[1], edem_data.shape[2])\n",
    "    \n",
    "    profile = edem_dataset.profile.copy()\n",
    "    profile.update(dtype=rasterio.float32, count=1, height=predictions.shape[0], width=predictions.shape[1])\n",
    "    \n",
    "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(predictions, 1)\n",
    "\n",
    "@timer\n",
    "def train_and_predict(temp_dir, output_dir, \n",
    "                      output_filename=\"predictions.tif\", \n",
    "                      feature_list=[\"s1\", \"esawc\"], \n",
    "                      model_type=\"lightgbm\"):\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    file_paths = {\n",
    "        \"s1\": os.path.join(temp_dir, \"aligned_s1.tif\"),\n",
    "        \"esawc\": os.path.join(temp_dir, \"aligned_esawc.tif\"),\n",
    "        \"ldem\": os.path.join(temp_dir, \"aligned_ldem_4749.tif\"),\n",
    "        \"edem\": os.path.join(temp_dir, \"aligned_edem_egm.tif\")\n",
    "    }\n",
    "\n",
    "    datasets = {}\n",
    "    try:\n",
    "        # Load datasets\n",
    "        for key in feature_list + [\"ldem\", \"edem\"]:\n",
    "            datasets[key], datasets[key + \"_data\"] = load_geotiff(file_paths[key])\n",
    "\n",
    "        # Preprocess data\n",
    "        features, labels = preprocess_data(feature_list, {k: datasets[k + \"_data\"] for k in feature_list}, datasets[\"ldem_data\"])\n",
    "\n",
    "        # Train model\n",
    "        model = train_model(features, labels, model_type=model_type)\n",
    "\n",
    "        # Save model\n",
    "        feature_str = \"_\".join(feature_list)\n",
    "        model_filename = f\"{model_type}_{feature_str}_{len(labels)}samples.joblib\"\n",
    "        model_filepath = os.path.join(output_dir, model_filename)\n",
    "        joblib.dump(model, model_filepath)\n",
    "        logger.info(f\"Model saved to {model_filepath}\")\n",
    "\n",
    "        # Predict and save output\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        predict_and_save(model, features, datasets[\"edem\"], output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close datasets\n",
    "        for key in datasets:\n",
    "            if isinstance(datasets[key], rasterio.io.DatasetReader):\n",
    "                datasets[key].close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    output_dir = os.path.join(temp_dir, \"output\")\n",
    "    train_and_predict(\n",
    "        temp_dir, \n",
    "        output_dir, \n",
    "        output_filename=\"lightgbm_edem_predictions.tif\",\n",
    "        feature_list=[\"edem\"],\n",
    "        model_type=\"lightgbm\"   # Options: \"lightgbm\", \"xgboost\", \"catboost\", \"rf\"\n",
    "    )\n",
    "\n",
    "# add resisuals \n",
    "#modely type and feature list should be on top and a function that attributtes the model_finaname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f11e750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 18:48:30,089 - INFO - Model R^2 Score: 0.11618484038197174\n",
      "2025-04-28 18:48:30,095 - INFO - Saved model to temp/output/CatBoost_esawc.joblib\n",
      "2025-04-28 18:48:30,358 - INFO - Total execution time: 50.94 seconds\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import logging\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def load_geotiff(file_path):\n",
    "    \"\"\"Loads a GeoTIFF file and returns the dataset and data array.\"\"\"\n",
    "    dataset = rasterio.open(file_path)\n",
    "    data = dataset.read()\n",
    "    return dataset, data\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_data(s1_data, esawc_data, ldem_data, selected_features):\n",
    "    \"\"\"\n",
    "    Preprocesses the raster data for model training, selecting features.\n",
    "\n",
    "    Args:\n",
    "        s1_data (numpy.ndarray): S1 data array.\n",
    "        esawc_data (numpy.ndarray): ESAWC data array.\n",
    "        ldem_data (numpy.ndarray): LDEM data array.\n",
    "        selected_features (list): List of features to use ('s1', 'esawc', 'ldem').\n",
    "\n",
    "    Returns:\n",
    "        tuple: (features_filtered, labels_filtered)\n",
    "            features_filtered: NumPy array of shape (n_samples, n_features)\n",
    "            labels_filtered: NumPy array of shape (n_samples,)\n",
    "    \"\"\"\n",
    "    feature_data = {\n",
    "        's1': s1_data,\n",
    "        'esawc': esawc_data,\n",
    "        'ldem': ldem_data,\n",
    "    }\n",
    "    flat_data = {}\n",
    "    for key in feature_data:\n",
    "        if feature_data[key] is not None:\n",
    "            flat_data[key] = feature_data[key].reshape(feature_data[key].shape[0], -1).T\n",
    "\n",
    "    if 's1' in selected_features and 'esawc' in selected_features and 'ldem' in selected_features:\n",
    "        if flat_data['s1'].shape[0] != flat_data['esawc'].shape[0] or flat_data['s1'].shape[0] != flat_data['ldem'].shape[0]:\n",
    "            raise ValueError(\"Number of pixels in s1, esawc, and ldem do not match.\")\n",
    "    elif 's1' in selected_features and 'esawc' in selected_features:\n",
    "         if flat_data['s1'].shape[0] != flat_data['esawc'].shape[0]:\n",
    "            raise ValueError(\"Number of pixels in s1, and esawc do not match.\")\n",
    "    elif 's1' in selected_features and 'ldem' in selected_features:\n",
    "         if flat_data['s1'].shape[0] != flat_data['ldem'].shape[0]:\n",
    "            raise ValueError(\"Number of pixels in s1, and ldem do not match.\")\n",
    "    elif 'esawc' in selected_features and 'ldem' in selected_features:\n",
    "         if flat_data['esawc'].shape[0] != flat_data['ldem'].shape[0]:\n",
    "            raise ValueError(\"Number of pixels in esawc, and ldem do not match.\")\n",
    "\n",
    "    selected_flat_data = [flat_data[feature] for feature in selected_features]\n",
    "    features = np.concatenate(selected_flat_data, axis=1)\n",
    "    labels_filtered = flat_data['ldem']\n",
    "    valid_indices = ~np.isnan(labels_filtered).any(axis=1)\n",
    "    features_filtered = features[valid_indices]\n",
    "    labels_filtered = labels_filtered[valid_indices].ravel()\n",
    "    return features_filtered, labels_filtered\n",
    "\n",
    "\n",
    "\n",
    "def train_model(features, labels, model_type, params=None):\n",
    "    \"\"\"\n",
    "    Trains a machine learning model.\n",
    "\n",
    "    Args:\n",
    "        features (numpy.ndarray): Features array.\n",
    "        labels (numpy.ndarray): Labels array.\n",
    "        model_type (str): Type of model ('RF', 'XGBoost', 'CatBoost', 'LightGBM').\n",
    "        params (dict, optional): Model parameters.  Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        object: Trained model.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    if model_type == 'RF':\n",
    "        model = RandomForestRegressor(random_state=42, **(params or {}))\n",
    "    elif model_type == 'XGBoost':\n",
    "        model = xgb.XGBRegressor(random_state=42, **(params or {}))\n",
    "    elif model_type == 'CatBoost':\n",
    "        model = cb.CatBoostRegressor(random_state=42, verbose=0, **(params or {}))\n",
    "    elif model_type == 'LightGBM':\n",
    "        model = lgb.LGBMRegressor(random_state=42, **(params or {}))\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid model type: {model_type}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    logger.info(f\"Model R^2 Score: {score}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def predict_and_save(model, features, edem_dataset, output_path):\n",
    "    \"\"\"Makes predictions and saves them to a GeoTIFF file.\"\"\"\n",
    "    edem_data = edem_dataset.read()\n",
    "    predictions_flat = model.predict(features)\n",
    "    predictions = predictions_flat.reshape(edem_data.shape[1], edem_data.shape[2])\n",
    "    profile = edem_dataset.profile.copy()\n",
    "    profile.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1,\n",
    "        height=predictions.shape[0],\n",
    "        width=predictions.shape[1],\n",
    "    )\n",
    "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(predictions, 1)\n",
    "\n",
    "\n",
    "\n",
    "def train_and_predict(temp_dir, output_dir, model_type, selected_features, params=None, output_filename=\"predictions.tif\"):\n",
    "    \"\"\"\n",
    "    Orchestrates the process of loading GeoTIFFs, training a model,\n",
    "    making predictions, and saving the results.\n",
    "\n",
    "    Args:\n",
    "        temp_dir (str): Path to the directory containing the GeoTIFF files.\n",
    "        output_dir (str): Path to the directory where the output GeoTIFF will be saved.\n",
    "        model_type (str): Type of model ('RF', 'XGBoost', 'CatBoost', 'LightGBM').\n",
    "        selected_features (list): List of features to use ('s1', 'esawc', 'ldem').\n",
    "        params (dict, optional): Model parameters. Defaults to None.\n",
    "        output_filename (str, optional): Name of the output GeoTIFF file. Defaults to \"predictions.tif\".\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    s1_path = os.path.join(temp_dir, \"aligned_s1.tif\")\n",
    "    esawc_path = os.path.join(temp_dir, \"aligned_esawc.tif\")\n",
    "    ldem_path = os.path.join(temp_dir, \"aligned_ldem_4749.tif\")\n",
    "    edem_path = os.path.join(temp_dir, \"aligned_edem_egm.tif\")\n",
    "\n",
    "    try:\n",
    "        s1_dataset, s1_data = load_geotiff(s1_path)\n",
    "        esawc_dataset, esawc_data = load_geotiff(esawc_path)\n",
    "        ldem_dataset, ldem_data = load_geotiff(ldem_path)\n",
    "        edem_dataset, edem_data = load_geotiff(edem_path)\n",
    "\n",
    "        features, labels = preprocess_data(s1_data, esawc_data, ldem_data, selected_features)\n",
    "        model = train_model(features, labels, model_type, params)\n",
    "\n",
    "        feature_string = '_'.join(selected_features)\n",
    "        model_filename = os.path.join(output_dir, f\"{model_type}_{feature_string}.joblib\")\n",
    "        joblib.dump(model, model_filename)\n",
    "        logger.info(f\"Saved model to {model_filename}\")\n",
    "\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        predict_and_save(model, features, edem_dataset, output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        if 's1_dataset' in locals(): s1_dataset.close()\n",
    "        if 'esawc_dataset' in locals(): esawc_dataset.close()\n",
    "        if 'ldem_dataset' in locals(): ldem_dataset.close()\n",
    "        if 'edem_dataset' in locals(): edem_dataset.close()\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    logger.info(f\"Total execution time: {duration:.2f} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #temp_dir = \"temp\"\n",
    "    output_dir = os.path.join(temp_dir, \"output\")\n",
    "    model_type = 'CatBoost'  # Or 'RF', 'XGBoost', 'CatBoost' 'LightGBM\n",
    "    selected_features = ['esawc']  # Example feature selection\n",
    "    # params = {\n",
    "    # 'objective': 'regression',  # Ensure this is set for your task\n",
    "    # 'metric': 'rmse',           # Or 'l2', 'l1', etc.\n",
    "    # 'boosting_type': 'gbdt',    # Or 'dart', 'goss'\n",
    "    # 'n_estimators': 1000,       # Number of boosting iterations\n",
    "    # 'learning_rate': 0.1,\n",
    "    # 'num_leaves': 31,           # Max number of leaves in one tree\n",
    "    # 'max_depth': -1,            # -1 means no limit\n",
    "    # 'min_data_in_leaf': 20,\n",
    "    # 'lambda_l1': 0.0,         # L1 regularization\n",
    "    # 'lambda_l2': 0.0,         # L2 regularization\n",
    "    # 'feature_fraction': 1.0,  # Fraction of features to consider for each tree\n",
    "    # 'bagging_fraction': 1.0,  # Fraction of data to sample for each iteration (if bagging_freq > 0)\n",
    "    # 'bagging_freq': 0,        # Frequency of bagging (0 means disable)\n",
    "    # 'verbose': -1\n",
    "    # }\n",
    "    params = {}\n",
    "    train_and_predict(temp_dir, output_dir, model_type, selected_features, params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21ab40d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w943 and h567 :: create DL datatraining with numpy equal size patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cb1c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d6fde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9cdb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean up the code below and improve upon it , add logging\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def read_dem(fpath, lval, hval, band=1):\n",
    "    src = rasterio.open(fpath)\n",
    "    data = src.read(band).astype(np.float32)  # Read specific band\n",
    "    ndv = src.nodata\n",
    "\n",
    "    # Build the valid data mask\n",
    "    mask = np.ones_like(data, dtype=bool)\n",
    "    if ndv is not None:\n",
    "        mask &= (data != ndv)\n",
    "    mask &= (data > lval) & (data < hval)\n",
    "\n",
    "    # Apply mask: set invalid pixels to np.nan\n",
    "    filtered_data = np.where(mask, data, np.nan)\n",
    "\n",
    "    return filtered_data, mask, src\n",
    "\n",
    "def read_geotiff(file_path):\n",
    "    dataset = rasterio.open(file_path)\n",
    "    data = dataset.read()\n",
    "    return data,dataset\n",
    "\n",
    "\n",
    "lval,hval=-99, 9000\n",
    "ldem, mask, ldem_src = read_dem('temp/aligned_ldem.tif', lval=lval, hval=hval)\n",
    "edem,  edem_src = read_geotiff('temp/aligned_edem_egm.tif')\n",
    "s1,  s1_src = read_geotiff('temp/aligned_s1.tif')\n",
    "esa,  esa_src = read_geotiff('temp/aligned_esawc.tif')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# --- Step 1: Prepare Features and Targets ---\n",
    "\n",
    "# Apply mask and handle potential single-band input\n",
    "def apply_mask(data, mask, band=0):\n",
    "    return np.where(mask, data[band] if data.ndim == 3 else data, np.nan)\n",
    "\n",
    "edem_masked = apply_mask(edem, mask)\n",
    "esa_masked  = apply_mask(esa, mask)\n",
    "s1_vv_masked = apply_mask(s1, mask, band=0)\n",
    "s1_vh_masked = apply_mask(s1, mask, band=1)\n",
    "ldem_masked = np.where(mask, ldem, np.nan)\n",
    "\n",
    "# Compute difference\n",
    "zdif_masked = edem_masked - ldem_masked\n",
    "\n",
    "# Stack input features (shape: 4, H, W)\n",
    "X_stack = np.stack([edem_masked, esa_masked, s1_vv_masked, s1_vh_masked], axis=0)\n",
    "\n",
    "# Flatten features and targets\n",
    "X_flat = X_stack.reshape(4, -1).T  # (n_samples, 4)\n",
    "Y1_flat = ldem_masked.flatten()    # (n_samples,)\n",
    "Y2_flat = zdif_masked.flatten()\n",
    "\n",
    "# Keep only valid (non-NaN) samples\n",
    "valid_mask = ~np.isnan(X_flat).any(axis=1) & ~np.isnan(Y1_flat) & ~np.isnan(Y2_flat)\n",
    "X_final = X_flat[valid_mask]\n",
    "Y_final = np.stack([Y1_flat[valid_mask], Y2_flat[valid_mask]], axis=1)  # (n_samples, 2)\n",
    "\n",
    "# --- Step 2: Train/Test Split (90% train, 10% test) ---\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_final, Y_final, test_size=0.1, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# --- Step 3: Train CatBoost Model (Multi-target) ---\n",
    "model = CatBoostRegressor(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "    depth=6,\n",
    "    loss_function='MultiRMSE',\n",
    "    verbose=100\n",
    ")\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# --- Step 4: Evaluate ---\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate separately for Y1 and Y2\n",
    "metrics = {}\n",
    "for i, target_name in enumerate(['LDEM', 'ZDIFF']):\n",
    "    rmse = mean_squared_error(Y_test[:, i], Y_pred[:, i], squared=False)\n",
    "    r2 = r2_score(Y_test[:, i], Y_pred[:, i])\n",
    "    metrics[target_name] = {'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "# Print evaluation results\n",
    "for target, scores in metrics.items():\n",
    "    print(f\"--- {target} ---\")\n",
    "    print(f\"RMSE: {scores['RMSE']:.4f}\")\n",
    "    print(f\"R:   {scores['R2']:.4f}\")\n",
    "\n",
    "\n",
    "# --- Step 5: Predict Full Image (using Unmasked Features) ---\n",
    "\n",
    "# Prepare unmasked feature stack\n",
    "edem_unmasked = edem[0] if edem.ndim == 3 else edem\n",
    "esa_unmasked  = esa[0] if esa.ndim == 3 else esa\n",
    "s1_vv_unmasked = s1[0]\n",
    "s1_vh_unmasked = s1[1]\n",
    "\n",
    "# Stack full feature arrays\n",
    "X_full_stack = np.stack([edem_unmasked, esa_unmasked, s1_vv_unmasked, s1_vh_unmasked], axis=0)  # (4, H, W)\n",
    "\n",
    "# Flatten for prediction\n",
    "X_full_flat = X_full_stack.reshape(4, -1).T  # (n_pixels, 4)\n",
    "\n",
    "# Predict\n",
    "Y_full_pred = model.predict(X_full_flat)  # shape (n_pixels, 2)\n",
    "\n",
    "# Reshape back to image\n",
    "H, W = edem_unmasked.shape\n",
    "Y1_pred_map = Y_full_pred[:, 0].reshape(H, W)  # Predicted LDEM\n",
    "Y2_pred_map = Y_full_pred[:, 1].reshape(H, W)  # Predicted ZDIFF\n",
    "\n",
    "pred_di = Y1_pred_map.copy()\n",
    "pred_id = edem_unmasked - Y2_pred_map\n",
    "\n",
    "pred_di = np.nan_to_num(pred_di, nan=-9999)\n",
    "pred_id = np.nan_to_num(pred_id, nan=-9999)\n",
    "\n",
    "\n",
    "# write to geotiff these :pred_di and pred_id and use properies from edem,  edem_src = read_geotiff('temp/aligned_edem_egm.tif')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def save_geotiff(output_path, array, reference_src, nodata_value=None):\n",
    "    \"\"\"\n",
    "    Save a numpy array as a GeoTIFF using spatial properties from a reference raster.\n",
    "\n",
    "    Parameters:\n",
    "    - output_path (str): Path to save the output GeoTIFF.\n",
    "    - array (np.ndarray): 2D array to save.\n",
    "    - reference_src (rasterio DatasetReader): Opened reference raster to copy CRS and transform.\n",
    "    - nodata_value (float or int, optional): Value to use for NoData (replaces NaNs if specified).\n",
    "    \"\"\"\n",
    "    if nodata_value is not None:\n",
    "        array = np.nan_to_num(array, nan=nodata_value)\n",
    "\n",
    "    with rasterio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=array.shape[0],\n",
    "        width=array.shape[1],\n",
    "        count=1,\n",
    "        dtype=array.dtype,\n",
    "        crs=reference_src.crs,\n",
    "        transform=reference_src.transform,\n",
    "        nodata=nodata_value\n",
    "    ) as dst:\n",
    "        dst.write(array, 1)  # Write to first band\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "save_geotiff('predicted_di.tif', pred_di, edem_src, nodata_value=-9999)\n",
    "save_geotiff('predicted_id.tif', pred_id, edem_src, nodata_value=-9999)\n",
    "\n",
    "if postprocessing:\n",
    "    xpath = \"aligned_edem_egm.tif\"\n",
    "    ypath = \"predicted_di.tif\"\n",
    "    opath = \"predicted_di_wr.tif\"\n",
    "    gwrdownxcale(xpath, ypath, opath,oaux=False,epsg_code=4979, clean=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
