{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b53e2c9",
   "metadata": {},
   "source": [
    "1. data [x]\n",
    "    - get the vrts for esa,ldar,s1,edem\n",
    "    - get the tifs from tls and rng \n",
    "\n",
    "2. datapre [+]\n",
    "    - clip by bbox and \n",
    "    - split train from test (cpu modelling continual ml?)\n",
    "\n",
    "3. datamod [tab]\n",
    "    - step 1: predit ldem \n",
    "    - step 2: get scores for with and without residual \n",
    "    - step 3: style transfer (+residual)\n",
    "    - step 4: expand prediction range by N pixels same model \n",
    "    - step 5: data fusion with ldem\n",
    "4. datamod [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cb77685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2af5d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdir4749 =  \"/media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749\"  \n",
    "ldem_vrt = f\"{outdir4749}/ldem_4749.vrt\"\n",
    "cmd = f\"gdalbuildvrt -overwrite {ldem_vrt} {outdir4749}/*.tif\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d99ac9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "esawc_vrt = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/esawc/esawc.vrt\"\n",
    "s1_vrt = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/s1/s1.vrt\"\n",
    "edem_egm_vrt = \"/media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/edem_egm/edem_egm.vrt\" \n",
    "\n",
    "tls_fn = \"/media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749/AngkorDTM50cm.tif\"\n",
    "rng_files = glob(\"/media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749/*.tif\")\n",
    "rgn_files = [f for f in rng_files if \"AngkorDTM50cm\" not in f and \"delta_s_m2070\" not in f]\n",
    "\n",
    "vrt_files = [esawc_vrt, s1_vrt,edem_egm_vrt, ldem_vrt] # these are the vrt files \n",
    "temp_dir = 'temp'\n",
    "os.makedirs(temp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53a97ff",
   "metadata": {},
   "source": [
    "esawc_vrt, s1_vrt,edem_egm_vrt  and tls_fn #set for self supervision SSL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c52987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference GeoTIFF: /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749/AngkorDTM50cm.tif\n",
      "  Bounding box: BoundingBox(left=103.73573115613353, bottom=13.317802380912203, right=103.99762004502242, top=13.47535793646776)\n",
      "  Transform: | 0.00, 0.00, 103.74|\n",
      "| 0.00,-0.00, 13.48|\n",
      "| 0.00, 0.00, 1.00|\n",
      "  Width: 2357, Height: 1418\n",
      "\n",
      "Processing /media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/esawc/esawc.vrt...\n",
      "  Saved aligned data to temp/aligned_esawc.tif\n",
      "\n",
      "Processing /media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/s1/s1.vrt...\n",
      "  Saved aligned data to temp/aligned_s1.tif\n",
      "\n",
      "Processing /media/ljp238/12TBWolf/ARCHIEVE/ARCHIVE_VRT/edem_egm/edem_egm.vrt...\n",
      "  Saved aligned data to temp/aligned_edem_egm.tif\n",
      "\n",
      "Processing /media/ljp238/12TBWolf/ARCHIEVE/LIDAR_DTM/reproj4749/ldem_4749.vrt...\n",
      "  Saved aligned data to temp/aligned_ldem_4749.tif\n"
     ]
    }
   ],
   "source": [
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "### use also xres and yres from tls_fn in addition to bbox so that the out are aligned with same spatial info and pixel counts\n",
    "def process_raster_data(tls_fn, vrt_files, temp_dir):\n",
    "    \"\"\"\n",
    "    Reads data from VRT files, aligning their spatial information and pixel counts\n",
    "    with a GeoTIFF file, and saves the extracted data as new GeoTIFF files.\n",
    "\n",
    "    Args:\n",
    "        tls_fn (str): Path to the reference GeoTIFF file.\n",
    "        vrt_files (list): List of paths to the VRT files to process.\n",
    "        temp_dir (str): Path to the directory where the output GeoTIFF files will be saved.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        # Open the reference GeoTIFF file to get spatial information\n",
    "        with rasterio.open(tls_fn) as tls_dataset:\n",
    "            # Get the bounding box, transform, width, and height of the reference GeoTIFF\n",
    "            bbox = tls_dataset.bounds\n",
    "            transform = tls_dataset.transform\n",
    "            out_width = tls_dataset.width\n",
    "            out_height = tls_dataset.height\n",
    "            print(f\"Reference GeoTIFF: {tls_fn}\")\n",
    "            print(f\"  Bounding box: {bbox}\")\n",
    "            print(f\"  Transform: {transform}\")\n",
    "            print(f\"  Width: {out_width}, Height: {out_height}\")\n",
    "\n",
    "            # Process each VRT file\n",
    "            for vrt_file in vrt_files:\n",
    "                try:\n",
    "                    # Open the VRT file\n",
    "                    with rasterio.open(vrt_file) as vrt_dataset:\n",
    "                        print(f\"\\nProcessing {vrt_file}...\")\n",
    "\n",
    "                        # Calculate the window based on the bounding box and transform of the reference GeoTIFF\n",
    "                        window = from_bounds(bbox.left, bbox.bottom, bbox.right, bbox.top, vrt_dataset.transform)\n",
    "\n",
    "                        # Read the data within the calculated window\n",
    "                        # Specify the desired output shape to ensure alignment\n",
    "                        try:\n",
    "                            data = vrt_dataset.read(window=window, out_shape=(vrt_dataset.count, out_height, out_width))\n",
    "                        except ValueError as e:\n",
    "                            print(f\"  Error reading data from {vrt_file} within the window: {e}\")\n",
    "                            print(\"  This might indicate a significant spatial mismatch.\")\n",
    "                            data = None\n",
    "\n",
    "                        if data is not None:\n",
    "                            # Update the metadata for the output GeoTIFF file\n",
    "                            out_meta = vrt_dataset.meta.copy()\n",
    "                            out_meta.update({\n",
    "                                \"driver\": \"GTiff\",\n",
    "                                \"height\": out_height,\n",
    "                                \"width\": out_width,\n",
    "                                \"transform\": transform,\n",
    "                                \"dtype\": data.dtype,\n",
    "                            })\n",
    "\n",
    "                            # Check for valid dimensions before writing\n",
    "                            if out_height > 0 and out_width > 0:\n",
    "                                # Create the output file name\n",
    "                                output_filename = os.path.join(temp_dir, f\"aligned_{os.path.basename(vrt_file)}\")\n",
    "                                output_filename = os.path.splitext(output_filename)[0] + \".tif\"\n",
    "\n",
    "                                # Write the data to a new GeoTIFF file\n",
    "                                with rasterio.open(output_filename, \"w\", **out_meta) as dst:\n",
    "                                    dst.write(data)\n",
    "                                print(f\"  Saved aligned data to {output_filename}\")\n",
    "                            else:\n",
    "                                print(f\"  Skipping {vrt_file}: Output dimensions are invalid (height={out_height}, width={out_width}).\")\n",
    "                                output_filename = os.path.join(temp_dir, f\"aligned_{os.path.basename(vrt_file)}\")\n",
    "                                output_filename = os.path.splitext(output_filename)[0] + \".tif\"\n",
    "                                shutil.copyfile(tls_fn, output_filename)\n",
    "                                print(f\"  Copied {tls_fn} to {output_filename} as a fallback.\")\n",
    "                        else:\n",
    "                            print(f\"  Skipping {vrt_file} due to issues reading data.\")\n",
    "                            output_filename = os.path.join(temp_dir, f\"aligned_{os.path.basename(vrt_file)}\")\n",
    "                            output_filename = os.path.splitext(output_filename)[0] + \".tif\"\n",
    "                            shutil.copyfile(tls_fn, output_filename)\n",
    "                            print(f\"  Copied {tls_fn} to {output_filename} as a fallback.\")\n",
    "\n",
    "                except rasterio.RasterioIOError as e:\n",
    "                    print(f\"  Error processing {vrt_file}: {e}\")\n",
    "                    print(f\"  Skipping {vrt_file} and continuing. Check if the file exists and is a valid raster.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"  An unexpected error occurred while processing {vrt_file}: {e}\")\n",
    "\n",
    "    except rasterio.RasterioIOError as e:\n",
    "        print(f\"Error opening {tls_fn}: {e}\")\n",
    "        print(\"Please ensure the file path is correct and the file is a valid GeoTIFF.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred with the reference GeoTIFF: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  \n",
    "    # Create a temporary directory if it doesn't exist\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "\n",
    "    process_raster_data(tls_fn, vrt_files, temp_dir)\n",
    "\n",
    "    # Clean up the temporary directory after processing (optional)\n",
    "    # shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "656346ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def load_geotiff(file_path):\n",
    "    dataset = rasterio.open(file_path)\n",
    "    data = dataset.read()\n",
    "    return dataset, data\n",
    "\n",
    "\n",
    "def preprocess_data(s1_data, esawc_data, ldem_data):\n",
    "    s1_flat = s1_data.reshape(s1_data.shape[0], -1).T\n",
    "    esawc_flat = esawc_data.reshape(esawc_data.shape[0], -1).T\n",
    "    ldem_flat = ldem_data.reshape(ldem_data.shape[0], -1).T\n",
    "\n",
    "    if s1_flat.shape[0] != esawc_flat.shape[0] or s1_flat.shape[0] != ldem_flat.shape[0]:\n",
    "        raise ValueError(\"Number of pixels in s1, esawc, and ldem do not match.\")\n",
    "\n",
    "    features = np.concatenate((s1_flat, esawc_flat), axis=1)\n",
    "    valid_indices = ~np.isnan(ldem_flat).any(axis=1)\n",
    "    features_filtered = features[valid_indices]\n",
    "    labels_filtered = ldem_flat[valid_indices].ravel()\n",
    "    return features_filtered, labels_filtered\n",
    "\n",
    "\n",
    "\n",
    "def train_model(features, labels):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    model = lgb.LGBMRegressor(random_state=42)\n",
    "    model.fit(features, labels)\n",
    "    score = model.score(X_test, y_test)\n",
    "    logger.info(f\"Model R^2 Score: {score}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def predict_and_save(model, features, edem_dataset, output_path):\n",
    "    edem_data = edem_dataset.read()\n",
    "    predictions_flat = model.predict(features)\n",
    "    predictions = predictions_flat.reshape(edem_data.shape[1], edem_data.shape[2])\n",
    "    profile = edem_dataset.profile.copy()\n",
    "    profile.update(\n",
    "        dtype=rasterio.float32,\n",
    "        count=1,\n",
    "        height=predictions.shape[0],\n",
    "        width=predictions.shape[1],\n",
    "    )\n",
    "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(predictions, 1)\n",
    "\n",
    "\n",
    "# add timer when bfore and after the function \n",
    "# add other function to select the model if RF, XGBoost, CatBoost, LightGBM, etc\n",
    "# add option to chose features , e.g. [s1, esawc, edem] or [s1,esawc], or ['edem'] and only select the features give \n",
    "# save the model with paramers as name of the features and num_of_iterations \n",
    "def train_and_predict_lightgbm(temp_dir, output_dir, output_filename=\"lgbm_predictions.tif\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    s1_path = os.path.join(temp_dir, \"aligned_s1.tif\")\n",
    "    esawc_path = os.path.join(temp_dir, \"aligned_esawc.tif\")\n",
    "    ldem_path = os.path.join(temp_dir, \"aligned_ldem_4749.tif\")\n",
    "    edem_path = os.path.join(temp_dir, \"aligned_edem_egm.tif\")\n",
    "\n",
    "    try:\n",
    "        s1_dataset, s1_data = load_geotiff(s1_path)\n",
    "        esawc_dataset, esawc_data = load_geotiff(esawc_path)\n",
    "        ldem_dataset, ldem_data = load_geotiff(ldem_path)\n",
    "        edem_dataset, edem_data = load_geotiff(edem_path)\n",
    "\n",
    "        features, labels = preprocess_data(s1_data, esawc_data, ldem_data)\n",
    "\n",
    "        model = train_model(features, labels)\n",
    "\n",
    "        model_filename = os.path.join(output_dir, \"lightgbm_model.joblib\")\n",
    "        joblib.dump(model, model_filename)\n",
    "\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        predict_and_save(model, features, edem_dataset, output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        if 's1_dataset' in locals(): s1_dataset.close()\n",
    "        if 'esawc_dataset' in locals(): esawc_dataset.close()\n",
    "        if 'ldem_dataset' in locals(): ldem_dataset.close()\n",
    "        if 'edem_dataset' in locals(): edem_dataset.close()\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     output_dir = os.path.join(temp_dir, \"output\")\n",
    "#     train_and_predict_lightgbm(temp_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1574ba39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695750f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73a290",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d005e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through the temp directory load s1 and esacf as features and ldem as label\n",
    "# remove the missing values filtering out the no data values by ldem \n",
    "# fit random forest model \n",
    "# save the model \n",
    "# make predictions on the entire feature set \n",
    "# write the predictions to a new tiff file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad4dfa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 18:39:48,874 - INFO - Starting train_and_predict...\n",
      "2025-04-28 18:39:48,876 - INFO - Starting load_geotiff...\n",
      "2025-04-28 18:39:48,901 - INFO - Finished load_geotiff in 0.03 seconds.\n",
      "2025-04-28 18:39:48,902 - INFO - Starting load_geotiff...\n",
      "2025-04-28 18:39:48,926 - INFO - Finished load_geotiff in 0.02 seconds.\n",
      "2025-04-28 18:39:48,927 - INFO - Starting load_geotiff...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 18:39:48,956 - INFO - Finished load_geotiff in 0.03 seconds.\n",
      "2025-04-28 18:39:48,958 - INFO - Starting preprocess_data...\n",
      "2025-04-28 18:39:49,022 - INFO - Finished preprocess_data in 0.06 seconds.\n",
      "2025-04-28 18:39:49,023 - INFO - Starting train_model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007877 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 255\n",
      "[LightGBM] [Info] Number of data points in the train set: 2673780, number of used features: 1\n",
      "[LightGBM] [Info] Start training from score 58726557525220922143210296142894989312.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 18:39:51,104 - INFO - LIGHTGBM Model R^2 Score: -0.6119\n",
      "2025-04-28 18:39:51,106 - INFO - Finished train_model in 2.08 seconds.\n",
      "2025-04-28 18:39:51,111 - INFO - Model saved to temp/output/lightgbm_edem_3342226samples.joblib\n",
      "2025-04-28 18:39:51,111 - INFO - Starting predict_and_save...\n",
      "2025-04-28 18:39:52,244 - INFO - Finished predict_and_save in 1.13 seconds.\n",
      "2025-04-28 18:39:52,247 - INFO - Finished train_and_predict in 3.37 seconds.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Setup logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        logger.info(f\"Starting {func.__name__}...\")\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        logger.info(f\"Finished {func.__name__} in {end - start:.2f} seconds.\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def load_geotiff(file_path):\n",
    "    dataset = rasterio.open(file_path)\n",
    "    data = dataset.read()\n",
    "    return dataset, data\n",
    "\n",
    "def select_features(feature_list, datasets):\n",
    "    feature_arrays = []\n",
    "    for feature in feature_list:\n",
    "        data = datasets[feature]\n",
    "        feature_arrays.append(data.reshape(data.shape[0], -1).T)\n",
    "    combined_features = np.concatenate(feature_arrays, axis=1)\n",
    "    return combined_features\n",
    "\n",
    "@timer\n",
    "def preprocess_data(feature_list, datasets, ldem_data):\n",
    "    features = select_features(feature_list, datasets)\n",
    "    ldem_flat = ldem_data.reshape(ldem_data.shape[0], -1).T\n",
    "    if features.shape[0] != ldem_flat.shape[0]:\n",
    "        raise ValueError(\"Mismatch in number of pixels between features and labels.\")\n",
    "    valid_indices = ~np.isnan(ldem_flat).any(axis=1)\n",
    "    features_filtered = features[valid_indices]\n",
    "    labels_filtered = ldem_flat[valid_indices].ravel()\n",
    "    return features_filtered, labels_filtered\n",
    "\n",
    "def get_model(model_type):\n",
    "    if model_type == \"lightgbm\":\n",
    "        return lgb.LGBMRegressor(random_state=42)\n",
    "    elif model_type == \"xgboost\":\n",
    "        return xgb.XGBRegressor(random_state=42)\n",
    "    elif model_type == \"catboost\":\n",
    "        return cb.CatBoostRegressor(verbose=0, random_state=42)\n",
    "    elif model_type == \"rf\":\n",
    "        return RandomForestRegressor(random_state=42)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "@timer\n",
    "def train_model(features, labels, model_type=\"lightgbm\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "    model = get_model(model_type)\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    logger.info(f\"{model_type.upper()} Model R^2 Score: {score:.4f}\")\n",
    "    return model\n",
    "\n",
    "@timer\n",
    "def predict_and_save(model, features, edem_dataset, output_path):\n",
    "    edem_data = edem_dataset.read()\n",
    "    predictions_flat = model.predict(features)\n",
    "    predictions = predictions_flat.reshape(edem_data.shape[1], edem_data.shape[2])\n",
    "    \n",
    "    profile = edem_dataset.profile.copy()\n",
    "    profile.update(dtype=rasterio.float32, count=1, height=predictions.shape[0], width=predictions.shape[1])\n",
    "    \n",
    "    with rasterio.open(output_path, \"w\", **profile) as dst:\n",
    "        dst.write(predictions, 1)\n",
    "\n",
    "@timer\n",
    "def train_and_predict(temp_dir, output_dir, \n",
    "                      output_filename=\"predictions.tif\", \n",
    "                      feature_list=[\"s1\", \"esawc\"], \n",
    "                      model_type=\"lightgbm\"):\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    file_paths = {\n",
    "        \"s1\": os.path.join(temp_dir, \"aligned_s1.tif\"),\n",
    "        \"esawc\": os.path.join(temp_dir, \"aligned_esawc.tif\"),\n",
    "        \"ldem\": os.path.join(temp_dir, \"aligned_ldem_4749.tif\"),\n",
    "        \"edem\": os.path.join(temp_dir, \"aligned_edem_egm.tif\")\n",
    "    }\n",
    "\n",
    "    datasets = {}\n",
    "    try:\n",
    "        # Load datasets\n",
    "        for key in feature_list + [\"ldem\", \"edem\"]:\n",
    "            datasets[key], datasets[key + \"_data\"] = load_geotiff(file_paths[key])\n",
    "\n",
    "        # Preprocess data\n",
    "        features, labels = preprocess_data(feature_list, {k: datasets[k + \"_data\"] for k in feature_list}, datasets[\"ldem_data\"])\n",
    "\n",
    "        # Train model\n",
    "        model = train_model(features, labels, model_type=model_type)\n",
    "\n",
    "        # Save model\n",
    "        feature_str = \"_\".join(feature_list)\n",
    "        model_filename = f\"{model_type}_{feature_str}_{len(labels)}samples.joblib\"\n",
    "        model_filepath = os.path.join(output_dir, model_filename)\n",
    "        joblib.dump(model, model_filepath)\n",
    "        logger.info(f\"Model saved to {model_filepath}\")\n",
    "\n",
    "        # Predict and save output\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        predict_and_save(model, features, datasets[\"edem\"], output_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        # Close datasets\n",
    "        for key in datasets:\n",
    "            if isinstance(datasets[key], rasterio.io.DatasetReader):\n",
    "                datasets[key].close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    output_dir = os.path.join(temp_dir, \"output\")\n",
    "    train_and_predict(\n",
    "        temp_dir, \n",
    "        output_dir, \n",
    "        output_filename=\"lightgbm_edem_predictions.tif\",\n",
    "        feature_list=[\"edem\"],\n",
    "        model_type=\"lightgbm\"   # Options: \"lightgbm\", \"xgboost\", \"catboost\", \"rf\"\n",
    "    )\n",
    "\n",
    "# add resisuals \n",
    "#modely type and feature list should be on top and a function that attributtes the model_finaname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f11e750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21ab40d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#w943 and h567 :: create DL datatraining with numpy equal size patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4cb1c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4749"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d6fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
